{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from torchsummary import summary\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import joblib  # スケーラーの保存用\n",
    "import sys\n",
    "import io\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPUスレッド数を設定\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSONデータの正規化と保存\n",
    "def normalize_json_data(input_path, output_path):\n",
    "    \"\"\"データを正規化して保存\"\"\"\n",
    "    try:\n",
    "        with open(input_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {input_path} not found.\")\n",
    "        return\n",
    "\n",
    "    inputs = np.array(data[\"inputs\"])\n",
    "    outputs = np.array(data[\"outputs\"])\n",
    "\n",
    "    # スケーラーのインスタンス化\n",
    "    input_scaler = MinMaxScaler()\n",
    "    output_scaler = MinMaxScaler()\n",
    "\n",
    "    # 入力と出力のスケーリング\n",
    "    inputs_normalized = input_scaler.fit_transform(inputs)\n",
    "    outputs_normalized = output_scaler.fit_transform(outputs)\n",
    "\n",
    "    # 正規化されたデータを保存\n",
    "    normalized_data = {\n",
    "        \"inputs\": inputs_normalized.tolist(),\n",
    "        \"outputs\": outputs_normalized.tolist()\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(normalized_data, f)\n",
    "    except IOError:\n",
    "        print(f\"Error: Unable to write to {output_path}.\")\n",
    "        return\n",
    "\n",
    "    # スケーラーを保存\n",
    "    joblib.dump(input_scaler, '../data/input_scaler.pkl')\n",
    "    joblib.dump(output_scaler, '../data/output_scaler.pkl')\n",
    "    print(\"Data normalization completed and scalers saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カスタムデータセットクラス\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        self.inputs = data[\"inputs\"]\n",
    "        self.outputs = data[\"outputs\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.inputs[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.outputs[idx], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# データローダーの生成\n",
    "def get_dataloader(json_path, batch_size=16):\n",
    "    dataset = CustomDataset(json_path)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=2):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../images/simple_model_graph.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルサマリーの表示\n",
    "def display_model_summary(model):\n",
    "    \"\"\"モデルのサマリーを表示し、ファイルに保存\"\"\"\n",
    "    stdout_backup = sys.stdout  # 標準出力をバックアップ\n",
    "    sys.stdout = io.StringIO()  # 新しい出力先を設定\n",
    "\n",
    "    summary(model, (1, 3))\n",
    "\n",
    "    # サマリーの内容を取得\n",
    "    summary_str = sys.stdout.getvalue()\n",
    "\n",
    "    # 標準出力を元に戻す\n",
    "    sys.stdout = stdout_backup\n",
    "\n",
    "    # サマリーをファイルに保存\n",
    "    with open(\"../data/model_summary.txt\", \"w\") as f:\n",
    "        f.write(summary_str)\n",
    "\n",
    "# ダミーの入力テンソルを作成 (バッチサイズ1)\n",
    "x = torch.randn(1, 3)  # 例: 入力が3次元のデータ\n",
    "\n",
    "# モデルを通して予測を取得\n",
    "model_show = SimpleModel()  # モデルインスタンスの作成\n",
    "y = model_show(x)\n",
    "\n",
    "# 計算グラフを作成\n",
    "dot = make_dot(y, params=dict(model_show.named_parameters()))\n",
    "\n",
    "# PNG形式で保存\n",
    "dot.format = \"png\"\n",
    "dot.render(\"../images/simple_model_graph\")  # \"simple_model_graph.png\" として保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのトレーニング\n",
    "def train_model(trial):\n",
    "    \"\"\"Optunaによるハイパーパラメータ最適化のためのトレーニング\"\"\"\n",
    "    # ベイズ最適化でハイパーパラメータを探索\n",
    "    lr = trial.suggest_loguniform('lr', 1e-6, 1e-1)\n",
    "    batch_size = trial.suggest_int('batch_size', 4, 64)\n",
    "\n",
    "    model = SimpleModel()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    dataloader = get_dataloader('../data/data_normalized.json', batch_size=batch_size)\n",
    "\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "\n",
    "    num_epochs = 10\n",
    "    progress_bar = tqdm(range(num_epochs), desc=\"Training Progress\", unit=\"epoch\")\n",
    "    for epoch in progress_bar:\n",
    "        epoch_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1} | Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    if not os.path.exists('../results'):\n",
    "        os.makedirs('../results')\n",
    "    torch.save(best_model, '../results/best_model.pth')\n",
    "\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optunaのベイズ最適化\n",
    "def perform_bayesian_optimization():\n",
    "    \"\"\"Optunaによるベイズ最適化の実行\"\"\"\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    n_trials = 10\n",
    "    progress_bar = tqdm(total=n_trials, desc=\"Bayesian Optimization Progress\", unit=\"trial\")\n",
    "\n",
    "    def callback(study, trial):\n",
    "        progress_bar.set_description(f\"Trial {trial.number+1} | Best Loss: {study.best_value:.6f}\")\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    study.optimize(train_model, n_trials=n_trials, callbacks=[callback])\n",
    "\n",
    "    progress_bar.close()\n",
    "    print(\"Best Hyperparameters:\", study.best_params)\n",
    "    print(\"Best Loss:\", study.best_value)\n",
    "\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論用関数\n",
    "def generate_output(input_data, model_path='../results/best_model.pth'):\n",
    "    \"\"\"入力データに基づいて推論を生成\"\"\"\n",
    "    model = SimpleModel()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    input_scaler = joblib.load('../data/input_scaler.pkl')\n",
    "    output_scaler = joblib.load('../data/output_scaler.pkl')\n",
    "\n",
    "    input_data_scaled = input_scaler.transform([input_data])\n",
    "    input_tensor = torch.tensor(input_data_scaled, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_scaled = model(input_tensor)\n",
    "        output = output_scaler.inverse_transform(output_scaled.numpy())\n",
    "\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-26 19:25:48,595] A new study created in memory with name: no-name-6a2dbd1b-4078-43e8-ac34-7062fb185acd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalization completed and scalers saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bayesian Optimization Progress:   0%|          | 0/10 [00:00<?, ?trial/s]/var/folders/gj/4tb33ww155x9v49s74kyhlcc0000gn/T/ipykernel_42082/451554939.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "Epoch 10 | Loss: 0.061074: 100%|██████████| 10/10 [00:00<00:00, 150.40epoch/s]\n",
      "[I 2024-11-26 19:25:48,680] Trial 0 finished with value: 0.05787527933716774 and parameters: {'lr': 0.00457259129635686, 'batch_size': 55}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.359010: 100%|██████████| 10/10 [00:00<00:00, 151.50epoch/s]\n",
      "[I 2024-11-26 19:25:48,752] Trial 1 finished with value: 0.3589381277561188 and parameters: {'lr': 1.725002522690253e-05, 'batch_size': 62}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.705803: 100%|██████████| 10/10 [00:00<00:00, 151.20epoch/s]s]\n",
      "[I 2024-11-26 19:25:48,826] Trial 2 finished with value: 0.10866852104663849 and parameters: {'lr': 0.05605553213501442, 'batch_size': 33}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.312286: 100%|██████████| 10/10 [00:00<00:00, 197.35epoch/s]s]\n",
      "[I 2024-11-26 19:25:48,886] Trial 3 finished with value: 0.31228572130203247 and parameters: {'lr': 1.7109984721210123e-05, 'batch_size': 56}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.086094: 100%|██████████| 10/10 [00:00<00:00, 171.65epoch/s]s]\n",
      "[I 2024-11-26 19:25:48,954] Trial 4 finished with value: 0.06944961845874786 and parameters: {'lr': 0.02371625826178692, 'batch_size': 35}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.294810: 100%|██████████| 10/10 [00:00<00:00, 155.98epoch/s]s]\n",
      "[I 2024-11-26 19:25:49,028] Trial 5 finished with value: 0.29481038451194763 and parameters: {'lr': 2.7769915985248474e-05, 'batch_size': 54}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.059076: 100%|██████████| 10/10 [00:00<00:00, 148.58epoch/s]s]\n",
      "[I 2024-11-26 19:25:49,103] Trial 6 finished with value: 0.05899469554424286 and parameters: {'lr': 0.0041864767495120355, 'batch_size': 36}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.062298: 100%|██████████| 10/10 [00:00<00:00, 87.82epoch/s]/s]\n",
      "[I 2024-11-26 19:25:49,225] Trial 7 finished with value: 0.0616796500980854 and parameters: {'lr': 0.0005898802863179674, 'batch_size': 11}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.183451: 100%|██████████| 10/10 [00:00<00:00, 157.09epoch/s]s]\n",
      "[I 2024-11-26 19:25:49,307] Trial 8 finished with value: 0.06745386868715286 and parameters: {'lr': 0.004315341428079936, 'batch_size': 38}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Epoch 10 | Loss: 0.080771: 100%|██████████| 10/10 [00:00<00:00, 303.90epoch/s]s]\n",
      "[I 2024-11-26 19:25:49,349] Trial 9 finished with value: 0.08077066391706467 and parameters: {'lr': 0.010307282107005817, 'batch_size': 61}. Best is trial 0 with value: 0.05787527933716774.\n",
      "Trial 10 | Best Loss: 0.057875: 100%|██████████| 10/10 [00:00<00:00, 13.32trial/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'lr': 0.00457259129635686, 'batch_size': 55}\n",
      "Best Loss: 0.05787527933716774\n",
      "Optimization completed. Best parameters: {'lr': 0.00457259129635686, 'batch_size': 55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # JSONデータの正規化\n",
    "    normalize_json_data('../data/data.json', '../data/data_normalized.json')\n",
    "\n",
    "    # Optunaによるベイズ最適化の実行\n",
    "    best_params = perform_bayesian_optimization()\n",
    "    print(\"Optimization completed. Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/4tb33ww155x9v49s74kyhlcc0000gn/T/ipykernel_42082/909357923.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: [3.5542031e-04 4.1440835e+03]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 推論テスト\n",
    "    sample_input = [73, 22, 22]\n",
    "    output = generate_output(sample_input)\n",
    "    print(f\"Generated Output: {output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
